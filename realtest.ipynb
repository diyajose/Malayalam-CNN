{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "def mplot(img,img2=None):\n",
    "    \n",
    "    cv2.namedWindow('img',cv2.WINDOW_NORMAL)\n",
    "    cv2.moveWindow('img', 600,300)\n",
    "    cv2.imshow('img',img)\n",
    "    if img2 is not None:\n",
    "        cv2.namedWindow('img2',cv2.WINDOW_NORMAL)\n",
    "        cv2.moveWindow('img', 600,600)\n",
    "        cv2.imshow('img2',img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "'''\n",
    "function to rearrange the contour bounding boxes. in default the contour bounding boxes comes in the sorted order of\n",
    "their y co-ordinates . this function returns a list of rectangles [(x1,y1,w1,h1),(x2,y2,w2,h2)...] which are sorted in\n",
    "the order of x axis on each line. a line will have all recangles of y coordinates between y and y+h of first rectangle '''\n",
    "def rearrange(cnt):\n",
    "    b_rect=[]\n",
    "    for c in cnt:\n",
    "        rect=cv2.boundingRect(c)\n",
    "        if rect[2] <=18 or rect[3] <= 18:\n",
    "            continue\n",
    "        b_rect.append(rect)\n",
    "    if b_rect==[]:\n",
    "        return []\n",
    "    p=b_rect[0][1]+b_rect[0][3]\n",
    "    #print('length of brect:',len(b_rect))\n",
    "    s_rect=[]\n",
    "    i=0\n",
    "    length=len(b_rect)\n",
    "    while i<length:\n",
    "        p=b_rect[i][1]+b_rect[i][3]\n",
    "        elem_on_line=[]#elements on a line\n",
    "        outer=True\n",
    "        while i<length and p>b_rect[i][1]:\n",
    "            elem_on_line.append(b_rect[i])\n",
    "            i+=1\n",
    "            outer=False\n",
    "        if outer:\n",
    "            i+=1\n",
    "        elem_on_line=sorted(elem_on_line) #,key=lambda x:x[0]\n",
    "        #print(elem_on_line,i)\n",
    "        s_rect.extend(elem_on_line)\n",
    "    return s_rect\n",
    "        \n",
    "\n",
    "'''\n",
    "clear_noice method clear noice from list of images and retrun cleared list of images\n",
    "'''\n",
    "def clear_noice(image,ellipse=(7,7),rect=(15,7)):\n",
    "    \n",
    "    threshold=128\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, ellipse )\n",
    "    kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, rect )\n",
    "    cnt=[]\n",
    "    grad = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n",
    "    _, bw = cv2.threshold(grad, threshold, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel2)\n",
    "    _,contours, hierarchy = cv2.findContours(connected.copy(), cv2.RETR_EXTERNAL ,cv2.CHAIN_APPROX_SIMPLE )\n",
    "    #reversing contour list to start processig from top\n",
    "    contours.reverse()\n",
    "    cnt.extend(contours)\n",
    "    #print('contour length:',len(contours))\n",
    "    #mplot(grad,connected)\n",
    "    return cnt\n",
    "\n",
    "def printChars():\n",
    "    for i,word in enumerate(seperated):\n",
    "        for j,char in enumerate(word):\n",
    "            mplot(char)\n",
    "            \n",
    "#predict word when a list of predicted classnames are given\n",
    "model2=load_model('/home/jabir/Project/MHCR/modelMHCR_gray_2.8.96.97.h5')\n",
    "\n",
    "mal=np.load('/home/jabir/Project/MHCR/malchar.npy')\n",
    "def predict_word(p_word):\n",
    "    pred='' \n",
    "    for i in p_word:\n",
    "        pred+=chr(mal[i])\n",
    "    return pred\n",
    "\n",
    "def splMean(img,thresh):\n",
    "    sum=0\n",
    "    nt=0\n",
    "    for row in img:\n",
    "        for elem in row:\n",
    "            if elem>thresh:\n",
    "                sum+=elem\n",
    "            else:\n",
    "                nt+=1\n",
    "    if sum!=0:\n",
    "        avg=sum/(img.size-nt)\n",
    "    else:avg=0\n",
    "    #print(avg)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img=cv2.resize(cv2.imread('/home/jabir/Project/MHCR/realtest/img1.jpg',0),(700,1000))\n",
    "#img=cv2.imread('/home/jabir/Project/MHCR/realtest/img1.jpg',0)\n",
    "#img=img[150:-200,30:-30]\n",
    "img2=img.copy()\n",
    "contours=clear_noice(img)\n",
    "#cutting the image into list of words\n",
    "s_rect=rearrange(contours)\n",
    "words=[]\n",
    "i=0\n",
    "for rect in s_rect:\n",
    "    x,y,w,h = rect\n",
    "    cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,0),2)\n",
    "    cv2.putText(img2,str(i),(x+w+10,y+h),0,0.3,(0,0,0))\n",
    "    word=(img[y:y+h,x:x+w])\n",
    "    ret,thresh4 = cv2.threshold(word,127,255,cv2.THRESH_TOZERO)\n",
    "    # inc is the increment for differ\n",
    "    inc=1*(255-splMean(thresh4,90))\n",
    "    #ret,thresh4 = cv2.threshold(word,127,255,cv2.THRESH_BINARY)\n",
    "    #thresh4 = cv2.adaptiveThreshold(word, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
    "    word=np.array([[min(j+inc,255) if j>90 else j for j in thresh4[k]] for k in range(len(thresh4))],dtype=np.uint8)\n",
    "    #word=thresh4\n",
    "    #mplot(thresh4,word)\n",
    "    words.append(word)\n",
    "    i+=1\n",
    "mplot(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Drawing bounding boxes on each words</h4><br/>\n",
    "<p> Here, word consists of list of words cropped.we are rearranging each word and drawing bounding rectangle to each characters  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "തല \n",
      "\n",
      "തറ \n",
      "\n",
      "മന \n",
      "\n",
      "പന \n",
      "\n",
      "അരണ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "seperated=[]\n",
    "for i in range(len(words)):\n",
    "    \n",
    "    c=clear_noice(words[i],ellipse=(3,3),rect=(2,2))\n",
    "    s_rect=rearrange(c)\n",
    "    #print(\"rect:\",s_rect)\n",
    "    chars=[]\n",
    "    if s_rect==[]:\n",
    "        continue\n",
    "    for rect in s_rect:\n",
    "        x,y,w,h = rect\n",
    "        char=words[i][y:y+h,x:x+w]\n",
    "        char= cv2.copyMakeBorder(char,20,20,20,20,cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "        char=cv2.resize(char,(86,86))\n",
    "        chars.append(char)\n",
    "        #mplot(char,words[i])\n",
    "    #print(chars)\n",
    "        #cv2.rectangle(words[i],(x,y),(x+w,y+h),(0,0,0),2)\n",
    "        #cv2.putText(words[i],str(i),(x+w+10,y+h),0,0.3,(0,0,0))\n",
    "           \n",
    "    #mplot(words[i])\n",
    "    seperated.append(chars)\n",
    "    \n",
    "\n",
    "#pred=model2.predict_class\n",
    "with open ('opt.txt','w') as file:\n",
    "    for i,word in enumerate(seperated):\n",
    "        if word ==[]:\n",
    "            continue\n",
    "        word=np.array(word)\n",
    "        word2=word\n",
    "        #print(word.shape)\n",
    "        pred=model2.predict_classes(word.reshape(-1,86,86,1))\n",
    "        #cv2.putText(words[i],predict_word(pred),(10,10),0,0.3,(0,255,0))   \n",
    "        print(predict_word(pred),'\\n')\n",
    "        file.write(predict_word(pred)+'\\n')\n",
    "        splMean(words[i],90)\n",
    "        mplot(words[i])\n",
    "    \n",
    "    \n",
    "mplot(img2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class and images\n",
    "#cls_and_img=np.load('/home/jabir/Project/MHCR/cls_labels.npy',cls_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#npy file for prediction\n",
    "#mal=np.load('/home/jabir/Project/MHCR/malchar.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "printChars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.imwrite('/home/jabir/Project/MHCR/realtest/charset2.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
